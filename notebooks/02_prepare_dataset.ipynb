{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d252ed74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ilya/Hackathon_JLR_2025/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of train 150908\n",
      "Size of validation 33049\n",
      "Size of test set 33050\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_from_disk\n",
    "from pathlib import Path\n",
    "\n",
    "RAW_PATH = Path(\"../data/raw/\") / \"bigvul.raw\"\n",
    "\n",
    "ds = load_from_disk(RAW_PATH)\n",
    "\n",
    "train_set = ds[\"train\"]\n",
    "validation_set = ds[\"validation\"]\n",
    "test_set = ds[\"test\"]\n",
    "\n",
    "print(f\"Size of train {len(train_set)}\")\n",
    "print(f\"Size of validation {len(validation_set)}\")\n",
    "print(f\"Size of test set {len(test_set)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58d61e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stripping columns\n",
    "train_set = train_set.remove_columns([\"codeLink\", \"commit_id\", \"CVE Page\", \"lang\", \"commit_message\", 'vul'])\n",
    "validation_set = validation_set.remove_columns([\"codeLink\", \"commit_id\", \"CVE Page\", \"lang\", \"commit_message\", 'vul'])\n",
    "test_set = test_set.remove_columns([\"codeLink\", \"commit_id\", \"CVE Page\", \"lang\", \"commit_message\", 'vul'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ba177c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of train 121933\n",
      "Size of validation 26739\n",
      "Size of test set 26626\n"
     ]
    }
   ],
   "source": [
    "# Remove entries with missing or empty CWE ID\n",
    "train_set = train_set.filter(lambda example: example[\"CWE ID\"] not in (None, \"\", \"None\"))\n",
    "validation_set = validation_set.filter(lambda example: example[\"CWE ID\"] not in (None, \"\", \"None\"))\n",
    "test_set = test_set.filter(lambda example: example[\"CWE ID\"] not in (None, \"\", \"None\"))\n",
    "\n",
    "print(f\"Size of train {len(train_set)}\")\n",
    "print(f\"Size of validation {len(validation_set)}\")\n",
    "print(f\"Size of test set {len(test_set)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "930a6f0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total applicable projects: 114\n",
      "Total not applicable projects: 183\n",
      "\n",
      "First 10 applicable projects:\n",
      "gpac\n",
      "libvips\n",
      "file\n",
      "zlib\n",
      "util-linux\n",
      "curl\n",
      "libmysofa\n",
      "collectd\n",
      "jerryscript\n",
      "oniguruma\n",
      "\n",
      "First 10 not applicable projects:\n",
      "libXrandr\n",
      "savannah\n",
      "OpenSC\n",
      "pdfresurrect\n",
      "rawstudio\n",
      "libvirt\n",
      "bzrtp\n",
      "libx11\n",
      "libbsd\n",
      "php-src\n"
     ]
    }
   ],
   "source": [
    "# Classification of applicable projects\n",
    "\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from google import genai\n",
    "\n",
    "class ProjectResponse(BaseModel):\n",
    "    applicable_projects: list[str] = Field(\n",
    "        ...,\n",
    "        description=\"List of projects that are applicable in automotive context.\"\n",
    "    )\n",
    "    not_applicable_projects: list[str] = Field(\n",
    "        ...,\n",
    "        description=\"List of projects that are not applicable in automotive context.\"\n",
    "    )\n",
    "    justification_per_project: list[str] = Field(\n",
    "        ...,\n",
    "        description=\"Justification for each project regarding its applicability in automotive context.\"\n",
    "    )\n",
    "\n",
    "\n",
    "def get_projects_prompt(projects_list_slice):\n",
    "    prompt = f\"\"\"\n",
    "You are an expert in automotive software development.\n",
    "Based on the provided list of project names, use your expertise to analyze the projects and determine their use and applicability in the automotive context.\n",
    "Applicability can be in different areas such as safety, security, performance, or compliance with automotive standards.\n",
    "For example, linux is applicable in automotive context as it is used in many ECUs as a an operating system.\n",
    "Strongswan is applicable in automotive context as it is used for secure communication in vehicle networks.\n",
    "Project needs to be applicable in the on-board context, not in the cloud, server, or simulation context. In short, the project should be used in the vehicle codebase.\n",
    "Please provide a detailed analysis of each project, including whether it is applicable or not, and the reasons for your assessment.\n",
    "Keep justification short and consice, ideally 1-2 sentences per project.\n",
    "Here is the list of projects:\n",
    "{'\\n'.join(projects_list_slice)}\"\"\"\n",
    "    return prompt\n",
    "\n",
    "\n",
    "with open('token', 'r') as file:\n",
    "    token = file.read().strip()\n",
    "    \n",
    "\n",
    "client = genai.Client(api_key=token)\n",
    "\n",
    "\n",
    "def determine_applicability_of_projects(prompt: str) -> ProjectResponse | None:\n",
    "    \"\"\"Determine if the vulnerability is applicable to automotive context.\"\"\"\n",
    "    try:\n",
    "        response = client.models.generate_content(\n",
    "            model=\"gemini-2.5-flash-preview-05-20\",\n",
    "            contents=prompt,\n",
    "            config={\n",
    "                \"response_mime_type\": \"application/json\",\n",
    "                \"response_schema\": ProjectResponse,\n",
    "            },\n",
    "        )\n",
    "        # if server error, return empty list\n",
    "    except genai.errors.ServerError as e:\n",
    "        print(f\"Server error: {e}\")\n",
    "        return None\n",
    "    return response.parsed\n",
    "\n",
    "\n",
    "from time import sleep\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "APPL_PROJECTS_PATH = Path(\"../data/meta/\") / \"applicable_projects.json\"\n",
    "\n",
    "unique_projects = set(train_set['project'])\n",
    "projects_list = list(unique_projects)\n",
    "\n",
    "def classify_projects_in_chunks():\n",
    "    chunk_step = 50\n",
    "    applicable = []\n",
    "    not_applicable = []\n",
    "    justifications = []\n",
    "    # Process the projects in chunks\n",
    "    for i in range(0, len(projects_list), chunk_step):\n",
    "        projects_list_slice = projects_list[i:i + chunk_step]\n",
    "        print(f\"Processing projects {i} to {i + chunk_step}...\")\n",
    "        while True:\n",
    "            response = determine_applicability_of_projects(get_projects_prompt(projects_list_slice))\n",
    "            if response:\n",
    "                print(f\"Processed projects {i} to {i + chunk_step}\")\n",
    "                print(f'More applicable projects: {len(response.applicable_projects)}')\n",
    "                print(f'More not applicable projects: {len(response.not_applicable_projects)}')\n",
    "                print(f'Appending {len(response.applicable_projects)} applicable projects and {len(response.not_applicable_projects)} not applicable projects.')\n",
    "                applicable += response.applicable_projects\n",
    "                not_applicable += response.not_applicable_projects\n",
    "                justifications += response.justification_per_project\n",
    "                print(\"Saving current results to file...\")\n",
    "                results = {\n",
    "                    \"applicable_projects\": applicable,\n",
    "                    \"not_applicable_projects\": not_applicable,\n",
    "                    \"justifications\": justifications\n",
    "                }\n",
    "                with open(APPL_PROJECTS_PATH, 'w') as f:\n",
    "                    json.dump(results, f, indent=4)\n",
    "                print(\"Results saved successfully.\")\n",
    "                break\n",
    "            else:\n",
    "                print(f\"Retrying for projects {i} to {i + chunk_step} due to server error...\")\n",
    "                sleep(5)\n",
    "\n",
    "\n",
    "with open(APPL_PROJECTS_PATH, 'r') as f:\n",
    "    projects_applicability_data = json.load(f)\n",
    "\n",
    "if not projects_applicability_data:\n",
    "    print(\"Projects have not been classified yet. Doing it now.\")\n",
    "    classify_projects_in_chunks()\n",
    "    with open(APPL_PROJECTS_PATH, 'r') as f:\n",
    "        projects_applicability_data = json.load(f)\n",
    "\n",
    "stats = {\n",
    "    \"total_applicable\": len(projects_applicability_data[\"applicable_projects\"]),\n",
    "    \"total_not_applicable\": len(projects_applicability_data[\"not_applicable_projects\"]),\n",
    "}\n",
    "\n",
    "print(\"Total applicable projects:\", stats[\"total_applicable\"])\n",
    "print(\"Total not applicable projects:\", stats[\"total_not_applicable\"])\n",
    "# Print the first 10 applicable projects\n",
    "print(\"\\nFirst 10 applicable projects:\")\n",
    "for project in projects_applicability_data[\"applicable_projects\"][:10]:\n",
    "    print(project)\n",
    "# Print the first 10 not applicable projects\n",
    "print(\"\\nFirst 10 not applicable projects:\")\n",
    "for project in projects_applicability_data[\"not_applicable_projects\"][:10]:\n",
    "    print(project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b76bc06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of train 53658\n",
      "Size of validation 12445\n",
      "Size of test set 12304\n"
     ]
    }
   ],
   "source": [
    "# Filter the dataset based on the applicability of projects\n",
    "applicable_projects_set = set(projects_applicability_data[\"applicable_projects\"])\n",
    "\n",
    "\n",
    "\n",
    "train_set = train_set.filter(lambda example: example[\"project\"] in applicable_projects_set)\n",
    "validation_set = validation_set.filter(lambda example: example[\"project\"] in applicable_projects_set)\n",
    "test_set = test_set.filter(lambda example: example[\"project\"] in applicable_projects_set)\n",
    "\n",
    "print(f\"Size of train {len(train_set)}\")\n",
    "print(f\"Size of validation {len(validation_set)}\")\n",
    "print(f\"Size of test set {len(test_set)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "abaeae1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 150908/150908 [00:00<00:00, 282286.60 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 33049/33049 [00:00<00:00, 145889.10 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 33050/33050 [00:00<00:00, 260011.01 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import DatasetDict\n",
    "from pathlib import Path\n",
    "\n",
    "# Assuming you filtered train, test, validation separately\n",
    "qualified_dataset = DatasetDict({\n",
    "    \"train\": train_set,\n",
    "    \"test\": validation_set,\n",
    "    \"validation\": test_set,\n",
    "})\n",
    "\n",
    "PATH_TO_QUALIFIED = Path(\"../data/processed/\") / \"with_cwe_projects_qualified\"\n",
    "\n",
    "ds.save_to_disk(PATH_TO_QUALIFIED)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
